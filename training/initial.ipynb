{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourist_destination</th>\n",
       "      <th>review_post</th>\n",
       "      <th>removed_special_charas_review_post</th>\n",
       "      <th>to_lower_case_review_post</th>\n",
       "      <th>removed_stop_words_review_post</th>\n",
       "      <th>lemmatized_words_review_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>An excellent place for family and friends to v...</td>\n",
       "      <td>An excellent place for family and friends to v...</td>\n",
       "      <td>an excellent place for family and friends to v...</td>\n",
       "      <td>excellent place family friends visit entrance ...</td>\n",
       "      <td>excellent place family friend visit entrance f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>A lovely place to be on a nice day.We were ple...</td>\n",
       "      <td>A lovely place to be on a nice day We were ple...</td>\n",
       "      <td>a lovely place to be on a nice day we were ple...</td>\n",
       "      <td>lovely place nice day pleasantly surprised ple...</td>\n",
       "      <td>lovely place nice day pleasantly surprised ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>Definitely one of the best places to visit in ...</td>\n",
       "      <td>Definitely one of the best places to visit in ...</td>\n",
       "      <td>definitely one of the best places to visit in ...</td>\n",
       "      <td>definitely best places visit baguio burnham pa...</td>\n",
       "      <td>definitely best place visit baguio burnham par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>I have always been looking at this park ever s...</td>\n",
       "      <td>I have always been looking at this park ever s...</td>\n",
       "      <td>i have always been looking at this park ever s...</td>\n",
       "      <td>looking park chance review park flexed view pa...</td>\n",
       "      <td>looking park chance review park flexed view pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>Very beautiful park with boating and cycling a...</td>\n",
       "      <td>Very beautiful park with boating and cycling a...</td>\n",
       "      <td>very beautiful park with boating and cycling a...</td>\n",
       "      <td>beautiful park boating cycling available insid...</td>\n",
       "      <td>beautiful park boating cycling available insid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14154</th>\n",
       "      <td>Teacher's Camp</td>\n",
       "      <td>There is no ghost ðŸ‘»ðŸ‘»ðŸ‘»Very affordable</td>\n",
       "      <td>There is no ghost  Very affordable</td>\n",
       "      <td>there is no ghost  very affordable</td>\n",
       "      <td>ghost affordable</td>\n",
       "      <td>ghost affordable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14155</th>\n",
       "      <td>Teacher's Camp</td>\n",
       "      <td>Classy place</td>\n",
       "      <td>Classy place</td>\n",
       "      <td>classy place</td>\n",
       "      <td>classy place</td>\n",
       "      <td>classy place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14156</th>\n",
       "      <td>Teacher's Camp</td>\n",
       "      <td>A beautiful view is cheap</td>\n",
       "      <td>A beautiful view is cheap</td>\n",
       "      <td>a beautiful view is cheap</td>\n",
       "      <td>beautiful view cheap</td>\n",
       "      <td>beautiful view cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14157</th>\n",
       "      <td>Teacher's Camp</td>\n",
       "      <td>well done</td>\n",
       "      <td>well done</td>\n",
       "      <td>well done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14158</th>\n",
       "      <td>Teacher's Camp</td>\n",
       "      <td>Mumu</td>\n",
       "      <td>Mumu</td>\n",
       "      <td>mumu</td>\n",
       "      <td>mumu</td>\n",
       "      <td>mumu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14159 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tourist_destination                                        review_post  \\\n",
       "0            Burnham Park  An excellent place for family and friends to v...   \n",
       "1            Burnham Park  A lovely place to be on a nice day.We were ple...   \n",
       "2            Burnham Park  Definitely one of the best places to visit in ...   \n",
       "3            Burnham Park  I have always been looking at this park ever s...   \n",
       "4            Burnham Park  Very beautiful park with boating and cycling a...   \n",
       "...                   ...                                                ...   \n",
       "14154      Teacher's Camp               There is no ghost ðŸ‘»ðŸ‘»ðŸ‘»Very affordable   \n",
       "14155      Teacher's Camp                                       Classy place   \n",
       "14156      Teacher's Camp                          A beautiful view is cheap   \n",
       "14157      Teacher's Camp                                          well done   \n",
       "14158      Teacher's Camp                                               Mumu   \n",
       "\n",
       "                      removed_special_charas_review_post  \\\n",
       "0      An excellent place for family and friends to v...   \n",
       "1      A lovely place to be on a nice day We were ple...   \n",
       "2      Definitely one of the best places to visit in ...   \n",
       "3      I have always been looking at this park ever s...   \n",
       "4      Very beautiful park with boating and cycling a...   \n",
       "...                                                  ...   \n",
       "14154                 There is no ghost  Very affordable   \n",
       "14155                                       Classy place   \n",
       "14156                          A beautiful view is cheap   \n",
       "14157                                          well done   \n",
       "14158                                               Mumu   \n",
       "\n",
       "                               to_lower_case_review_post  \\\n",
       "0      an excellent place for family and friends to v...   \n",
       "1      a lovely place to be on a nice day we were ple...   \n",
       "2      definitely one of the best places to visit in ...   \n",
       "3      i have always been looking at this park ever s...   \n",
       "4      very beautiful park with boating and cycling a...   \n",
       "...                                                  ...   \n",
       "14154                 there is no ghost  very affordable   \n",
       "14155                                       classy place   \n",
       "14156                          a beautiful view is cheap   \n",
       "14157                                          well done   \n",
       "14158                                               mumu   \n",
       "\n",
       "                          removed_stop_words_review_post  \\\n",
       "0      excellent place family friends visit entrance ...   \n",
       "1      lovely place nice day pleasantly surprised ple...   \n",
       "2      definitely best places visit baguio burnham pa...   \n",
       "3      looking park chance review park flexed view pa...   \n",
       "4      beautiful park boating cycling available insid...   \n",
       "...                                                  ...   \n",
       "14154                                   ghost affordable   \n",
       "14155                                       classy place   \n",
       "14156                               beautiful view cheap   \n",
       "14157                                                NaN   \n",
       "14158                                               mumu   \n",
       "\n",
       "                            lemmatized_words_review_post  \n",
       "0      excellent place family friend visit entrance f...  \n",
       "1      lovely place nice day pleasantly surprised ple...  \n",
       "2      definitely best place visit baguio burnham par...  \n",
       "3      looking park chance review park flexed view pa...  \n",
       "4      beautiful park boating cycling available insid...  \n",
       "...                                                  ...  \n",
       "14154                                   ghost affordable  \n",
       "14155                                       classy place  \n",
       "14156                               beautiful view cheap  \n",
       "14157                                                NaN  \n",
       "14158                                               mumu  \n",
       "\n",
       "[14159 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../csv/cleaned/cleaned_variations_review_posts2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "tourist_destinations = data['tourist_destination']\n",
    "print(len(tourist_destinations.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Burnham Park\n",
       "1          Burnham Park\n",
       "2          Burnham Park\n",
       "3          Burnham Park\n",
       "4          Burnham Park\n",
       "              ...      \n",
       "14154    Teacher's Camp\n",
       "14155    Teacher's Camp\n",
       "14156    Teacher's Camp\n",
       "14157    Teacher's Camp\n",
       "14158    Teacher's Camp\n",
       "Name: tourist_destination, Length: 14159, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourist_destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range = (1, 1))\n",
    "tfv_text = tfv.fit_transform(data['lemmatized_words_review_post'].values.astype('U'))\n",
    "\n",
    "words = tfv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14159x10341 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 140804 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'place', 'family', 'friend', 'visit', 'entrance', 'fee', 'lake', 'ride', 'boat', 'park', 'ground', 'ride', 'small', 'bike', 'place', 'recommend', 'night', 'get', 'quite', 'dark', 'spot', 'morning', 'superb', 'experience', 'definitely', 'want', 'come']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "words = list(sent_to_words(data['lemmatized_words_review_post'].values.tolist()))\n",
    "print(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(words)\n",
    "# Create Corpus\n",
    "texts = words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(10303 unique tokens: ['bike', 'boat', 'come', 'dark', 'definitely']...)\n"
     ]
    }
   ],
   "source": [
    "dict_ = corpora.Dictionary(words)\n",
    "print(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using the dictionary \n",
    "doc_term_matrix = [dict_.doc2bow(i) for i in words]\n",
    "print(doc_term_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=19, passes=20, \n",
    "random_state=20, chunksize = 10000, eval_every = 10, iterations = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.032*\"awesome\" + 0.015*\"like\" + 0.013*\"place\" + 0.012*\"view\" + 0.011*\"lot\" '\n",
      "  '+ 0.010*\"people\" + 0.009*\"local\" + 0.009*\"good\" + 0.008*\"display\" + '\n",
      "  '0.008*\"season\"'),\n",
      " (1,\n",
      "  '0.063*\"art\" + 0.035*\"great\" + 0.034*\"museum\" + 0.020*\"view\" + 0.017*\"place\" '\n",
      "  '+ 0.017*\"cafe\" + 0.017*\"work\" + 0.017*\"artist\" + 0.016*\"nice\" + '\n",
      "  '0.015*\"artwork\"'),\n",
      " (2,\n",
      "  '0.025*\"inside\" + 0.018*\"nan\" + 0.018*\"went\" + 0.017*\"building\" + '\n",
      "  '0.014*\"allowed\" + 0.012*\"people\" + 0.012*\"hotel\" + 0.010*\"line\" + '\n",
      "  '0.009*\"long\" + 0.009*\"slippery\"'),\n",
      " (3,\n",
      "  '0.054*\"place\" + 0.020*\"nice\" + 0.017*\"time\" + 0.012*\"view\" + 0.012*\"photo\" '\n",
      "  '+ 0.012*\"good\" + 0.011*\"flower\" + 0.010*\"area\" + 0.009*\"spend\" + '\n",
      "  '0.008*\"enjoy\"'),\n",
      " (4,\n",
      "  '0.043*\"horse\" + 0.026*\"view\" + 0.023*\"riding\" + 0.023*\"park\" + 0.018*\"ride\" '\n",
      "  '+ 0.016*\"place\" + 0.011*\"mine\" + 0.011*\"mansion\" + 0.010*\"horseback\" + '\n",
      "  '0.009*\"baguio\"'),\n",
      " (5,\n",
      "  '0.030*\"view\" + 0.023*\"entrance\" + 0.023*\"place\" + 0.021*\"fee\" + '\n",
      "  '0.019*\"peso\" + 0.018*\"picture\" + 0.016*\"lot\" + 0.014*\"igorot\" + '\n",
      "  '0.012*\"photo\" + 0.012*\"good\"'),\n",
      " (6,\n",
      "  '0.025*\"place\" + 0.018*\"morning\" + 0.014*\"just\" + 0.013*\"early\" + '\n",
      "  '0.012*\"try\" + 0.012*\"ice\" + 0.012*\"best\" + 0.011*\"cream\" + 0.010*\"food\" + '\n",
      "  '0.009*\"strawberry\"'),\n",
      " (7,\n",
      "  '0.059*\"place\" + 0.039*\"amazing\" + 0.033*\"view\" + 0.023*\"nice\" + '\n",
      "  '0.023*\"relaxing\" + 0.022*\"air\" + 0.018*\"fresh\" + 0.016*\"tree\" + '\n",
      "  '0.015*\"beautiful\" + 0.014*\"old\"'),\n",
      " (8,\n",
      "  '0.047*\"park\" + 0.035*\"place\" + 0.027*\"baguio\" + 0.016*\"boat\" + '\n",
      "  '0.015*\"visit\" + 0.015*\"burnham\" + 0.013*\"activity\" + 0.012*\"enjoy\" + '\n",
      "  '0.011*\"city\" + 0.011*\"lot\"'),\n",
      " (9,\n",
      "  '0.038*\"place\" + 0.034*\"tourist\" + 0.031*\"baguio\" + 0.018*\"spot\" + '\n",
      "  '0.017*\"just\" + 0.017*\"city\" + 0.013*\"good\" + 0.013*\"time\" + 0.010*\"visit\" + '\n",
      "  '0.009*\"attraction\"'),\n",
      " (10,\n",
      "  '0.056*\"parking\" + 0.021*\"space\" + 0.020*\"garden\" + 0.019*\"entrance\" + '\n",
      "  '0.018*\"fee\" + 0.017*\"area\" + 0.016*\"park\" + 0.014*\"better\" + 0.014*\"just\" + '\n",
      "  '0.014*\"traffic\"'),\n",
      " (11,\n",
      "  '0.050*\"baguio\" + 0.036*\"church\" + 0.033*\"road\" + 0.025*\"city\" + '\n",
      "  '0.023*\"mass\" + 0.022*\"cathedral\" + 0.017*\"landmark\" + 0.015*\"just\" + '\n",
      "  '0.012*\"session\" + 0.011*\"sunday\"'),\n",
      " (12,\n",
      "  '0.137*\"place\" + 0.055*\"love\" + 0.031*\"family\" + 0.025*\"great\" + '\n",
      "  '0.023*\"nice\" + 0.018*\"visit\" + 0.013*\"best\" + 0.012*\"cold\" + 0.010*\"nature\" '\n",
      "  '+ 0.010*\"friend\"'),\n",
      " (13,\n",
      "  '0.141*\"place\" + 0.109*\"nice\" + 0.065*\"good\" + 0.025*\"view\" + 0.024*\"visit\" '\n",
      "  '+ 0.019*\"great\" + 0.017*\"relax\" + 0.017*\"beautiful\" + 0.014*\"picture\" + '\n",
      "  '0.012*\"experience\"'),\n",
      " (14,\n",
      "  '0.039*\"market\" + 0.038*\"food\" + 0.032*\"buy\" + 0.032*\"good\" + 0.027*\"price\" '\n",
      "  '+ 0.022*\"lot\" + 0.022*\"place\" + 0.020*\"night\" + 0.020*\"cheap\" + '\n",
      "  '0.015*\"item\"'),\n",
      " (15,\n",
      "  '0.100*\"strawberry\" + 0.029*\"farm\" + 0.022*\"picking\" + 0.020*\"head\" + '\n",
      "  '0.019*\"lion\" + 0.016*\"pick\" + 0.015*\"fresh\" + 0.015*\"experience\" + '\n",
      "  '0.012*\"baguio\" + 0.012*\"place\"'),\n",
      " (16,\n",
      "  '0.098*\"baguio\" + 0.070*\"place\" + 0.039*\"visit\" + 0.038*\"beautiful\" + '\n",
      "  '0.036*\"city\" + 0.020*\"nice\" + 0.017*\"cool\" + 0.015*\"good\" + 0.012*\"stop\" + '\n",
      "  '0.011*\"view\"'),\n",
      " (17,\n",
      "  '0.044*\"jam\" + 0.034*\"ube\" + 0.029*\"buy\" + 0.023*\"best\" + 0.022*\"pasalubong\" '\n",
      "  '+ 0.019*\"market\" + 0.019*\"coffee\" + 0.017*\"product\" + 0.016*\"good\" + '\n",
      "  '0.016*\"price\"'),\n",
      " (18,\n",
      "  '0.034*\"place\" + 0.018*\"people\" + 0.016*\"souvenir\" + 0.016*\"great\" + '\n",
      "  '0.015*\"friendly\" + 0.011*\"just\" + 0.011*\"maintained\" + 0.010*\"lot\" + '\n",
      "  '0.010*\"clean\" + 0.010*\"beautiful\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 3 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.5220164859917509\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=words, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: {}'.format(coherence_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Machine Based\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectors_train, vectors_test, topics_train, topics_test = train_test_split(tfv_text, tourist_destinations, test_size = 0.1, random_state = 50)\n",
    "\n",
    "# For Rule Based\n",
    "texts_train, texts_test, topics2_train, topics2_test = train_test_split(tfv_text, tourist_destinations, test_size = 0.1, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "matrix = CountVectorizer()\n",
    "vectors = matrix.fit_transform(data['lemmatized_words_review_post'].values.astype('U')).toarray()\n",
    "\n",
    "# For Machine Based\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectors_train, vectors_test, topics_train, topics_test = train_test_split(vectors, tourist_destinations, test_size = 0.10, random_state = 50)\n",
    "\n",
    "# For Rule Based\n",
    "texts_train, texts_test, topics2_train, topics2_test = train_test_split(vectors, tourist_destinations, test_size = 0.10, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel = \"linear\")\n",
    "clf.fit(vectors_train, topics_train)\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(vectors_train.toarray(), topics_train)\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# clf = DecisionTreeClassifier()\n",
    "# clf.fit(vectors_train, topics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>Our Lady of the Atonement Cathedral (Baguio Ca...</td>\n",
       "      <td>Our Lady of the Atonement Cathedral (Baguio Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>Our Lady of the Atonement Cathedral (Baguio Ca...</td>\n",
       "      <td>Our Lady of the Atonement Cathedral (Baguio Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Wright Park</td>\n",
       "      <td>Wright Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>Baguio Botanical Garden</td>\n",
       "      <td>Baguio Botanical Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>Lionâ€™s Head</td>\n",
       "      <td>Lionâ€™s Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>Heritage Hill and Nature Park Garden</td>\n",
       "      <td>Heritage Hill and Nature Park Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Burnham Park</td>\n",
       "      <td>Burnham Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>Wright Park</td>\n",
       "      <td>Wright Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>Baguio Night Market</td>\n",
       "      <td>Baguio Night Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8027</th>\n",
       "      <td>Lionâ€™s Head</td>\n",
       "      <td>Lionâ€™s Head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1416 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  actual  \\\n",
       "6000   Our Lady of the Atonement Cathedral (Baguio Ca...   \n",
       "6882   Our Lady of the Atonement Cathedral (Baguio Ca...   \n",
       "4341                                         Wright Park   \n",
       "5646                             Baguio Botanical Garden   \n",
       "7878                                         Lionâ€™s Head   \n",
       "...                                                  ...   \n",
       "10113               Heritage Hill and Nature Park Garden   \n",
       "366                                         Burnham Park   \n",
       "4954                                         Wright Park   \n",
       "3473                                 Baguio Night Market   \n",
       "8027                                         Lionâ€™s Head   \n",
       "\n",
       "                                                 predict  \n",
       "6000   Our Lady of the Atonement Cathedral (Baguio Ca...  \n",
       "6882   Our Lady of the Atonement Cathedral (Baguio Ca...  \n",
       "4341                                         Wright Park  \n",
       "5646                             Baguio Botanical Garden  \n",
       "7878                                         Lionâ€™s Head  \n",
       "...                                                  ...  \n",
       "10113               Heritage Hill and Nature Park Garden  \n",
       "366                                         Burnham Park  \n",
       "4954                                         Wright Park  \n",
       "3473                                 Baguio Night Market  \n",
       "8027                                         Lionâ€™s Head  \n",
       "\n",
       "[1416 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "topics_pred_svm = clf.predict(vectors_test)\n",
    "\n",
    "actual_predict = pd.DataFrame()\n",
    "actual_predict[\"actual\"] = topics_test\n",
    "actual_predict[\"predict\"] = topics_pred_svm\n",
    "\n",
    "actual_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                       precision    recall  f1-score   support\n",
      "\n",
      "                                                              Baguio Botanical Garden       0.47      0.63      0.54       109\n",
      "                                                                   Baguio City Market       0.70      0.76      0.73        93\n",
      "                                                Baguio Country Club Christmas Village       0.46      0.42      0.44        40\n",
      "                                                                  Baguio Night Market       0.68      0.74      0.71        99\n",
      "                                                                          Bell Church       0.61      0.43      0.50        47\n",
      "                                                                        BenCab Museum       0.69      0.68      0.68        84\n",
      "                                                                         Burnham Park       0.51      0.54      0.53       101\n",
      "                                                                Good Shepherd Convent       0.73      0.56      0.63        34\n",
      "                                                 Heritage Hill and Nature Park Garden       0.65      0.58      0.62        77\n",
      "                                                                 Igorot Stone Kingdom       0.51      0.57      0.54        84\n",
      "                                                                          Lionâ€™s Head       0.43      0.55      0.48        93\n",
      "                                                          Mines View Observation Deck       0.55      0.68      0.61       106\n",
      "Our Lady of the Atonement Cathedral (Baguio Cathedral) - Archdiocese of Nueva Segovia       0.69      0.69      0.69        96\n",
      "                                      Strawberry Farm - Home of Giant Strawberry Cake       0.75      0.64      0.69        90\n",
      "                                                                     Tam-awan Village       0.58      0.35      0.44        63\n",
      "                                                                       Teacher's Camp       0.77      0.34      0.48        29\n",
      "                                                            Tree Top Adventure Baguio       0.83      0.52      0.64        29\n",
      "                                                                     Valley of Colors       0.68      0.54      0.60        28\n",
      "                                                                          Wright Park       0.56      0.46      0.51       114\n",
      "\n",
      "                                                                             accuracy                           0.59      1416\n",
      "                                                                            macro avg       0.62      0.56      0.58      1416\n",
      "                                                                         weighted avg       0.60      0.59      0.59      1416\n",
      "\n",
      "0.5903954802259888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(topics_test, topics_pred_svm))\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(topics_test, topics_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# load it again\n",
    "with open('../models/svm_classifier.pkl', 'rb') as fid:\n",
    "    clf = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier\n",
    "with open('../models/svm_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "test_df  = pd.DataFrame({'review' : ['I want to pick fresh strawberries']})\n",
    "\n",
    "tfv2 = TfidfVectorizer(ngram_range = (1, 1), stop_words = \"english\")\n",
    "tfv_text2 = tfv2.fit_transform([test_df['review'][0]]).todense()\n",
    "\n",
    "words2 = tfv2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but SVC is expecting 10341 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39;49mpredict(tfv_text2))\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:791\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    789\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 791\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    792\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:414\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    399\u001b[0m     \u001b[39m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[39m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[0;32m    415\u001b[0m     predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[0;32m    416\u001b[0m     \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:592\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    589\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[1;32m--> 592\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    593\u001b[0m         X,\n\u001b[0;32m    594\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    595\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    596\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    597\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    598\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    599\u001b[0m     )\n\u001b[0;32m    601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[0;32m    602\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4 features, but SVC is expecting 10341 features as input."
     ]
    }
   ],
   "source": [
    "print(clf.predict(tfv_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675b13e958f0d0236d13cdfe08a1df3882cae564fa23a2e7e5eb1f2c6c632b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
